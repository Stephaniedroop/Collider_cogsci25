########################################################################
############################# CESM functions ###########################

# Functions to run counterfactual simulation and assign a quantity of responsibility to each of several causes.
# 1) function that calculates all possible observations of the causes ('worlds') and gets conditional probabilities and posterior
# Needs inputs of:
# -- cause variables, assuming these happen either 0,1 and their strengths, assuming in a vector of prob 0, prob 1
# -- causal structure, whether disjunctive or conjunctive

# 2) function to get counterfactuals and effect size:
# -- simulates counterfactuals by resampling from the prior for vars with p=1-s where s=stability to real world.
# -- prints out correlation of effect with each causal variable across these simulated counterfactual worlds.

library(tidyverse)

# ------------- Create world combos df ----------------- 
# A function to get all world combinations

# Gives varying obs: if c then 5 x 4, if d then 7 x 4 (reason is we need all combos of unobs, even incoherent, for lesion later)
world_combos <- function(params, structure) { 
  causes2 <- rownames(params)
  n_causes <- nrow(params)
  #causes <- rownames(params)
  # Make a df of all combinations of variable settings
  df <- expand.grid(rep(list(c(0,1)),n_causes), KEEP.OUT.ATTRS = F)
  # ... with variables as the column names
  colnames(df) <- c(causes2)
  worlds <- nrow(df)
  # Calculate EFFECT (E) depending on whether structure is disjunctive or conjunctive
  if (structure=="conjunctive") { 
    df$E <- as.numeric((df[1] & df[2]) & (df[3] & df[4])) 
  }
  if (structure=="disjunctive") { 
    df$E <- as.numeric((df[1] & df[2]) | (df[3] & df[4])) 
  }
  mat <- as.matrix(df[,1:4])
  # Replace every cell with the relevant indexed edge strength from params
  for (k in 1:worlds){
    for (cause in causes2) {
      a <- params[cause,df[k,cause]+1] # It needs the '+1' because r indexes from 1 not 0
      mat[k,cause] <- a 
    }
  }
  colnames(df)[1:4] <- causes1 #c('A', 'Au', 'B', 'Bu')
  df <- cbind(df, mat)
  # For each row of df, the parameter is now the product of the same row of the intermediate mat
  df$Pr <- apply(mat, 1, prod) # This is how likely that setting of causes is. Sums to 1
  df$PrUn <- df$peA*df$peB
  df$index <- 1:nrow(df)
  df$structure <- structure 
  
  # This chunk gives all combinations of Au and Bu to all the real sets of ABE. 
  # (We need all combinations, even those with 0 posterior, because later a lesion samples by prior instead)
  result <- df %>% group_by(A, B, E) %>%
    group_split() %>%
    lapply(function(group) {
      combinations <- expand.grid(Au = c(0,1), Bu=c(0,1))
      cbind(group[1, c("A", "B", "E")], combinations)
    }) %>%
    bind_rows()
  
  # Then we want to merge this back in to the df
  test <- merge(x = result, y = df, by = c('A','B','Au','Bu'))
  
  # Calculate posterior. Some are incoherent but will be removed later
  df1 <- test %>% 
    group_by(A, B, E.y, E.x) %>% 
    mutate(posterior = PrUn/sum(PrUn)) %>%  #groupPost = cur_group_id()
    ungroup() 
  
  # Now set the impossible ones to 0
  df1$posterior[df1$E.x!=df1$E.y] <- 0 
  
  df1 <- df1 %>% 
    group_by(A, B, E.x) %>% 
    mutate(groupPost = cur_group_id()) %>% 
    ungroup() 
  
  df1
} 

# ------------- CESM FUNCTION ----------------------------
# A function to run the generic minimal CESM. Takes arguments of:
# - params that lists the base rates and strengths of exog noise u vars
# - a df of all the world combos with probs, generated by function world_combos
# (some redundancy across these two functions but probably ok)

# A function to get CESM scores, as per Bramley&Droop implementation using Pearson correlation, and all 'jiggling' of worlds at once
get_cfs <- function(params, structure, df) { 
  n_causes <- nrow(params)
  p <- params[,2] # The p_eachvar==1 
  pvec <- rep(p, times = N_cf) # Turn it into a 40k vec
  mp <- df %>% relocate(Au, .before = B) # assuming we can do it in one line - reassignment takes a lot of time
  # Add new columns then fill them
  new_cols <- c('mA', 'mAu', 'mB', 'mBu', 'cfsA', 'cfaAu', 'cfsB', 'cfsBu', 'Sum')
  mp[new_cols] <- NA
  worlds <- nrow(df) #as.integer(nrow(df)/2)
  
  # Loop through possible world settings: it's actually not 16 but 20(c) and 28(d) because we need scores for all combinations even post=0
  for (c_ix in 1:worlds)
  {
    # STABILITY: Generate vector of random numbers. The ones outside stability s are to be resampled. Put T for them
    resample <- runif(n_causes*N_cf) > s # 40k vec, with T for ones higher than the stability param 
    # Take the current case as the real world
    case <- mp[c_ix,] 
    # Repeat the cause settings of the current world, to be cf sampled
    cf_csrep <- rep(as.numeric(case[1:n_causes]), times = N_cf) # 40k vec
    # Now resample from its prior each value whose place in resample was set to TRUE in stability step
    cf_csrep[resample] <- rbinom(sum(resample), size = 1, prob = pvec[resample])  
    # Express these generated counterfactuals in tabular form again
    cfs <- data.frame(matrix(cf_csrep, nrow = N_cf, byrow = T))
    colnames(cfs) <- causes1
    
    # Recalculate determinative effect for these simulated cf worlds
    if (structure=="conjunctive") { 
      cfs$E <- as.numeric((cfs[1] & cfs[2]) & (cfs[3] & cfs[4])) 
    }
    if (structure=="disjunctive") { 
      cfs$E <- as.numeric((cfs[1] & cfs[2]) | (cfs[3] & cfs[4])) 
    }
    
    # Add column T/F for whether the Effect in the cf worlds matches the real world
    cfs$Match <- cfs$E==case$E.x
    # Set up empty vector of correlations (ie causal effect sizes), one for each cause
    cor_sizes <- rep(NA, n_causes)
    realcfs <- rep(NA, n_causes)
    for (cause in 1:n_causes)
    {
      # ..And then populate! (the second part sets correlation negative when cause pushes against effect taking state it took)
      cor_sizes[cause] <- cor(cfs[[causes1[cause]]], cfs$Match, method = 'pearson') * (c(-1,1)[as.numeric(case[[causes1[cause]]])+1])
      realcfs[cause] <- sum(cfs[[causes1[cause]]]!=case[[causes1[cause]]])
    }
    # Now put these correlations in the mp df, along with the number of actual cfs simulated, and how many times the Effect matched 
    mp[c_ix, 18:21] <- t(cor_sizes)
    mp[c_ix, 22:25] <- t(realcfs)
    mp[c_ix, 26] <- sum(cfs$E==case$E.x)
    mp$index <- 1:nrow(mp)
  }
  mp
}

# --------- QUILLIEN AND LUCAS 2023 --------------
# A new version in the same way as the paper

# Steps: p.6 supplementary material
# a) Simulate a large number of cf worlds: randomly sample exog vars then set endog vars by structural equations.
# Compute standard deviation of each variable 
# b) For each world, simulate cf twin by setting each cause C to a new random value. Then set endog vars 
# c) For each pair of worlds, compute specific causal effect of C on E by taking ratio of change in value E to C
# multiplied by standardising factor
# d) Take average across all pairs of worlds

# ---------- Anchors on the actual world ---------------

# Takes input of prior prob params 0/1, structure ('conjunctive','disjunctive') and a df made by 'world_combos' above.
# Naively you'd think the df has to be 16, but here do it for 20 (conj: 5x4) or 28 (disj: 7x4) rows because we need all combinations of unobserved vars for each SEM
get_cfs_ql <- function(params, structure, df) { # 
  n_causes <- nrow(params)
  p <- params[,2] # The p_eachvar==1 
  pvec <- rep(p, times = N_cf) # Turn it into a 40k vec 
  worlds <- nrow(df) 
  mp <- df %>% relocate(Au, .before = B) # assuming we can do it in one line - reassignment takes a lot of time
  # Add new columns then fill them
  new_cols <- c('mA', 'mAu', 'mB', 'mBu', 'cfsA', 'cfaAu', 'cfsB', 'cfsBu', 'Sum')
  mp[new_cols] <- NA
  
  # This whole loop calculates cfs and effects anchored on each 'real world'
  
  # STEP a) Simulate worlds from the causal model 
  for (c_ix in 1:worlds)
  { 
    # STABILITY: Generate vector of random numbers. The ones outside stability s are to be resampled. Put T for them
    resample <- runif(n_causes*N_cf) > s # 40k vec, with T for ones higher than the stability param 
    # Take the current case
    case <- mp[c_ix,]
    # Repeat the cause settings of the current world 10000 times
    case_vec <- rep(as.numeric(case[1:n_causes]), times = N_cf) # 40k vec
    
    # Now resample from its prior each value whose place in resample was set to TRUE in stability step
    case_vec[resample] <- rbinom(sum(resample), size = 1, prob = pvec[resample]) 
    mat <- matrix(case_vec, nrow = N_cf, ncol = n_causes, byrow = TRUE)
    
    # Calculate effect (determinative)
    if (structure=="conjunctive") { 
      E <- as.numeric((mat[,1] & mat[,2]) & (mat[,3] & mat[,4]))
    }
    if (structure=="disjunctive") { 
      E <- as.numeric((mat[,1] & mat[,2]) | (mat[,3] & mat[,4]))
    }
    
    # Get the standard deviations 
    sds <- apply(mat, 2, sd)
    sdE <- sd(E)
    
    # Get the standardising factors (needed in step c)
    sd_f <- sds/sdE
    
    # STEP b) Simulate counterfactual twin worlds all at once: the same size vector this time all 0.5
    twins <- matrix(rbinom(N_cf * n_causes, size = 1, prob = 0.5), nrow = N_cf, ncol = n_causes)
    
    # Compute separate vector of endogenous Effects for each twin C, keeping other Vs same
    # (First for conjunctive SEMs)
    if (structure=="conjunctive") { 
      nC1E <- as.numeric((twins[,1] & mat[,2]) & (mat[,3] & mat[,4]))
      nC2E <- as.numeric((mat[,1] & twins[,2]) & (mat[,3] & mat[,4]))
      nC3E <- as.numeric((mat[,1] & mat[,2]) & (twins[,3] & mat[,4]))
      nC4E <- as.numeric((mat[,1] & mat[,2]) & (mat[,3] & twins[,4]))
    }
    if (structure=="disjunctive") { 
      nC1E <- as.numeric((twins[,1] & mat[,2]) | (mat[,3] & mat[,4]))
      nC2E <- as.numeric((mat[,1] & twins[,2]) | (mat[,3] & mat[,4]))
      nC3E <- as.numeric((mat[,1] & mat[,2]) | (twins[,3] & mat[,4]))
      nC4E <- as.numeric((mat[,1] & mat[,2]) | (mat[,3] & twins[,4]))
    }
    
    # Then wrap into a matrix
    matE <- cbind(nC1E, nC2E, nC3E, nC4E)
    
    # STEP c) Compute specific causal effect for each pair of worlds
    
    # First the change in E:
    deltaE <- matE-E
    
    # Then changes in C: they are all the same simulated from prior so can use the same ones
    deltaC <- twins-mat
    
    # Ratio of change
    ratio <- deltaE/deltaC # It produces one of five possible values: NaN, -Inf, 0, -1, Inf, 1
    
    # Replace the /0 ones with NA
    ratio[is.infinite(ratio)] <- NA
    
    # Multiply the ratios by the standardising factors to get Specific Causal Effect
    sce <- sweep(ratio, 2, sd_f, '*')
    
    # STEP d) Compute causal score by averaging across worlds
    k <- colSums(sce, na.rm = TRUE) / N_cf 
    mp[c_ix, 18:21] <- t(k)
    mp$index <- 1:nrow(mp)
  }
  mp
}