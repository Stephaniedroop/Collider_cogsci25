library(tidyverse)
library(rjson)
library(ggnewscale) # Download these if you don't have them
library(here)
csvList <- lapply(list.files(here("Data", "batch"), full.names = TRUE), read.csv, stringsAsFactors = F)
#--------------- 1. Get ppt data  -------------------
source('01preprocessing.R') # Collates individual data csvs of both main batch and pilot
#--------------- 1. Get ppt data  -------------------
source('Scripts/01preprocessing.R') # Collates individual data csvs of both main batch and pilot
#--------------- 1. Get ppt data  -------------------
source(here::here('Scripts', '01preprocessing.R')) # Collates individual data csvs of both main batch and pilot
#------- 2. Create parameters, run cesm, get model predictions and save them ------------
source(here::here('Scripts', '02setParams.R')) # Output: probability vectors for use in...
source(here::here('03getModelPreds.R')) # Loads static `cesmUtils.R` functions and uses it to 1) generate world settings then 2) CESM model predictions for those
source(here::here('Scripts', '03getModelPreds.R')) # Loads static `cesmUtils.R` functions and uses it to 1) generate world settings then 2) CESM model predictions for those
source(here::here('Scripts', 'cesmUtils.R')) # Functions for running the cesm
source(here::here('Scripts', 'optimUtils.R')) # Functions for optimising the model fits
source(here::here('Scripts', '03getModelPreds.R')) # Loads static `cesmUtils.R` functions and uses it to 1) generate world settings then 2) CESM model predictions for those
View(all)
source(here::here('Scripts', '04modelProcessing.R')) # Takes average of 10 model runs, wrangles, splits out 0/1 node values and other user friendly
source(here::here('Scripts', '04modelProcessing.R')) # Takes average of 10 model runs, wrangles, splits out 0/1 node values and other user friendly
load("/Users/stephaniedroop/Documents/GitHub/ColliderCogsci25/Data/ModelData/all.rda")
View(all)
source(here::here('Scripts', '04modelProcessing.R')) # Takes average of 10 model runs, wrangles, splits out 0/1 node values and other user friendly
#
load(here::here('Data', 'Data.Rdata', verbose = T) # This is one big df, 'data', 3408 obs of 18 ie. 284 ppts
#
load(here::here('Data', 'Data.Rdata', verbose = T)) # This is one big df, 'data', 3408 obs of 18 ie. 284 ppts
#
load(here::here('Data', 'Data.Rdata')) # This is one big df, 'data', 3408 obs of 18 ie. 284 ppts
View(data)
load(here::here('Data', 'ModelData', 'tidiedPreds.rda')) # 576 of 26 - 576 rows because: 3 pgroups x 12 trialtypes x 4 nodes x 4 prior possible settings of unobserved variables
# -------------3. Results: fit model, compare predictions, plot etc
source(here::here('Scripts', '05getLesions.R')) # modules and lesions put with bytrial participant data, to get rda called 'modelAndDataUnfit.csv'
#
load(here::here('Data', 'Data.Rdata')) # This is one big df, 'data', 3348 obs of 18 ie. 284 ppts (without the 5 very first pilot - they were in paper but not here)
load(here::here('Data', 'ModelData', 'tidiedPreds.rda')) # 576 of 26 - 576 rows because: 3 pgroups x 12 trialtypes x 4 nodes x 4 prior possible settings of unobserved variables
# -------------3. Results: fit model, compare predictions, plot etc
source(here::here('Scripts', '05getLesions.R')) # modules and lesions put with bytrial participant data, to get rda called 'modelAndDataUnfit.csv'
View(modelAndData)
View(models)
View(models2)
View(df_list)
View(Actual)
# -------------3. Results: fit model, compare predictions, plot etc
source(here::here('Scripts', '05getLesions.R')) # modules and lesions put with bytrial participant data, to get rda called 'modelAndDataUnfit.csv'
View(full)
View(mp)
View(Actual)
View(all)
View(all)
View(Actual)
View(mp)
write.csv(all, 'all.csv')
write.csv(mp, 'mp.csv')
Actual <- mp |>
group_by(pgroup, trialtype, node3) |>
slice(1) |>
select(pgroup, trialtype, node3, Actual) |>
ungroup()
View(Actual)
Actual <- mp |>
group_by(pgroup, trialtype, node3) |>
summarise(Actual = first(Actual), .groups = "drop")
#
load(here::here('Data', 'Data.Rdata')) # This is one big df, 'data', 3348 obs of 18 ie. 284 ppts (without the 5 very first pilot - they were in paper but not here)
load(here::here('Data', 'ModelData', 'tidiedPreds.rda')) # 576 of 26 - 576 rows because: 3 pgroups x 12 trialtypes x 4 nodes x 4 prior possible settings of unobserved variables
mp <- all # For legacy reasons it is renamed in the wholescript, maybe tidy later
mp$pgroup <- as.factor(mp$pgroup)
mp$node3 <- as.factor(mp$node3)
mp$trialtype <- as.factor(mp$trialtype)
mp$structure <- as.factor(mp$structure)
mp$E.x <- as.factor(mp$E.x)
mp$E.y <- as.factor(mp$E.y)
# Condition 1
mp <- mp |> #
mutate(Actual = case_when(
node2 == 'A' ~ A==E.x,
node2 == 'B' ~ B==E.x,
node2 == 'Au' ~ Au==E.x,
node2 == 'Bu' ~ Bu==E.x
))
str(mp)
# Condition 2 - many of these are already caught but just to catch the extras
mp$Actual[mp$A=='0' & mp$node3=='Au=1'] <- FALSE
mp$Actual[mp$B=='0' & mp$node3=='Bu=1'] <- FALSE
mp <- mp |>
mutate(cesmActual = cesm*Actual)
# FULL
full <- mp |>
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(full = sum(cesmActual*posterior))
# Uses plain cesm before treatment for Actual
noAct <- mp |>  #2
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noAct = sum(cesm*posterior))
# Uses the cesm after treatment for Actuality, but then uses prior of unobserved variables rather than posterior
noInf <- mp |>  #3
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noInf = sum(cesmActual*PrUn))
# Uses plain cesm before treatment for Actual, and prior of unobserved variables rather than posterior
noActnoInf <- mp |>  #6
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noActnoInf = sum(cesm*PrUn))
getpost <- mp |> # 120 obs of 4
filter(!node2 %in% c('A','B')) |>
group_by(pgroup, trialtype, node) |>
summarise(post = sum(posterior),
prior = sum(PrUn))
# Merge this back in to the main model predictions
postmp <- merge(mp, getpost, by = c('pgroup', 'trialtype', 'node'), all.x = TRUE)
# For A and B, gives 1 when E matches, 0 if not. This sets B to 1 for actual cause, eg. if B=0 when E=0
postmp <- postmp |> #
mutate(Act1 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post,
node2 == 'Bu' ~ post
))
# We decided (with Quillien) we have to give only the Actual causal score for the observed variables
postmp <- postmp |> #
mutate(noSelect = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ post*Actual,
node2 == 'Bu' ~ post*Actual
))
noSelect <- postmp |>
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noSelect = mean(noSelect))
noActnoSelect <- postmp |>
group_by(pgroup, trialtype, node3, .drop=F) |>
summarise(noActnoSelect = mean(Act1))
#------- Lesion both inference and selection ---------
# As before, but it's the prior instead of posterior
mp <- mp |> #
mutate(Act3 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ peA*Actual,
node2 == 'Bu' ~ peB*Actual
))
noInfnoSelect <- mp |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noInfnoSelect = mean(Act3))
mp <- mp |> #
mutate(Act2 = case_when(
node2 == 'A' ~ Actual,
node2 == 'B' ~ Actual,
node2 == 'Au' ~ peA,
node2 == 'Bu' ~ peB
))
noActnoInfnoSelect <- mp |>
group_by(pgroup, trialtype, node3, .drop = F) |>
summarise(noActnoInfnoSelect = mean(Act2))
# ---------- Merge models back together --------------------
df_list <- list(full,
noAct,
noInf,
noSelect,
noActnoInf,
noActnoSelect,
noInfnoSelect,
noActnoInfnoSelect)
models <- df_list |>
reduce(full_join, by = c('pgroup', 'trialtype', 'node3'))
#
Actual <- mp |>
select(pgroup, trialtype, node3, Actual) |>
distinct()
Actual <- mp |>
group_by(pgroup, trialtype, node3) |>
summarise(Actual = first(Actual), .groups = "drop")
test <- mp |>
group_by(pgroup, trialtype, node3) |>
summarise(n_distinct_actual = n_distinct(Actual))
View(test)
models2 <- merge(models, Actual, all.x = TRUE)
# -------------3. Results: fit model, compare predictions, plot etc
source(here::here('Scripts', '05getLesions.R')) # modules and lesions put with bytrial participant data, to get rda called 'modelAndDataUnfit.csv'
View(modelAndData)
View(models2)
Actual <- mp |>
select(pgroup, trialtype, node3, Actual) |>
distinct()
View(Actual)
Actual <- mp |>
select(pgroup, trialtype, node3, Actual)
Actual <- Actual |> distinct()
View(Actual)
# Get values of Actual for each combination of pgroup, trialtype, node3
Actual <- mp |>
group_by(pgroup, trialtype, node3) |>
summarise(Actual = first(Actual), .groups = "drop")
View(Actual)
str(Actual)
str(models)
View(models)
models <- models |> ungroup()
# Get values of Actual for each combination of pgroup, trialtype, node3
Actual <- mp |>
group_by(pgroup, trialtype, node3) |>
summarise(Actual = first(Actual), .groups = "drop")
models2 <- merge(models, Actual, all.x = TRUE)
models <- df_list |>
reduce(full_join, by = c('pgroup', 'trialtype', 'node3')) |>
ungroup()
# Get values of Actual for each combination of pgroup, trialtype, node3
Actual <- mp |>
group_by(pgroup, trialtype, node3) |>
summarise(Actual = first(Actual), .groups = "drop")
models2 <- merge(models, Actual, all.x = TRUE)
# -------------3. Results: fit model, compare predictions, plot etc
source(here::here('Scripts', '05getLesions.R')) # modules and lesions put with bytrial participant data, to get rda called 'modelAndDataUnfit.csv'
View(modelAndData)
View(modelAndData)
# read in the rda
load(here::here('Data', 'modelData', 'modelAndDataUnfit.rda')) # df: 288 obs of 14
View(modelAndData)
source(here::here('Scripts', 'optimUtils.R')) # Functions for optimising the model fits
source(here::here('Scripts', 'optimUtils.R')) # Functions for optimising the model fits
source(here::here('Scripts', '06optimise.R') # Get predictions and optimise: Get nll and tau for each model
source(here::here('Scripts', '06optimise.R')) # Get predictions and optimise: Get nll and tau for each model
source(here::here('Scripts', '06optimise.R')) # Get predictions and optimise: Get nll and tau for each model
# read in the rda
load(here::here('Data', 'modelData', 'modelAndDataUnfit.rda')) # df: 288 obs of 14
# Let's create variables coding the actual observation
df.map<-data.frame(condition=c('c1','c2','c3','c4','c5','d1','d2','d3','d4','d5','d6','d7'),
A=c(0,0,1,1,1, 0,0,0,1,1,1,1),
B=c(0,1,0,1,1, 0,1,1,0,0,1,1),
E=c(0,0,0,0,1, 0,0,1,0,1,0,1))
for (i in 1:nrow(df))
{
df$B[i]<-df.map$B[df.map$condition==df$trialtype[i]]
df$E[i]<-df.map$E[df.map$condition==df$trialtype[i]]
}
# Allocate Boolean status for Include: F for noisy or nonsense answers (e.g. answering A=0 when they can see A=1).
# This is only for the cogsci paper, to handle 1.4% of data. later we handle it with a noise parameter epsilon
# It also has the advantage of any var being NA (e.g. if a ppt never answered A=0) being excluded
df <- df |>
mutate(include = !( (node3=='B=0' & B==1) | (node3=='B=1' & B==0) | (node3=='A=0' & A==1) | (node3=='A=1' & A==0)))
source(here::here('Scripts', 'optimUtils.R')) # Functions for optimising the model fits
source(here::here('Scripts', '06optimise.R')) # Get predictions and optimise: Get nll and tau for each model
library(RColorBrewer)
source(here::here('Scripts', '07reportingFigs.R'))
View(fitforplot)
source(here::here('Scripts', '07reportingFigs.R'))
source(here::here('Scripts', '07reportingFigs.R'))
source(here::here('Scripts', '07reportingFigs.R'))
# Get individual csvs into a list
csvList <- lapply(list.files(here("Data", "batch"), full.names = TRUE),
read.csv, stringsAsFactors = F)
